# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: 8 числовых признаков (без `sample_id`)
- Пропуски: нет
- "Подлости" датасета: разные шкалы признаков + шумовые признаки

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: 3 числовых признака (без `sample_id`), один из них шумовой
- Пропуски: нет
- "Подлости" датасета: нелинейная структура + выбросы + шумовой признак

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000, 33)
- Признаки: 30 числовых + 2 категориальных (без `sample_id`)
- Пропуски: есть, суммарно 5915 пропусков в числовых колонках
- "Подлости" датасета: высокая размерность, категориальные признаки и пропуски

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: масштабирование всех числовых признаков (`StandardScaler`), заполнение пропусков в числовых медианой (`SimpleImputer`), категориальные признаки (для dataset-04) кодировались через `OneHotEncoder(handle_unknown="ignore")`.
- Поиск гиперпараметров:
  - KMeans: `k` в диапазоне 2–10, фиксировали `random_state=42` и `n_init=10`.
  - DBSCAN: перебор `eps` и `min_samples` по сетке для каждого датасета; в выбор лучшей модели включались только варианты с долей шума ≤ 0.3.
  - Критерий выбора лучшего: максимум `silhouette_score` (DBSCAN считается по non-noise точкам).
- Метрики: `silhouette_score` (выше лучше), `davies_bouldin_score` (ниже лучше), `calinski_harabasz_score` (выше лучше). Для DBSCAN метрики считались только на non-noise точках, отдельно фиксировалась доля шума.
- Визуализация: PCA(2D) scatter для лучшего решения на каждом датасете. Отдельные графики подбора параметров: silhouette vs k.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
- Один из:
  - DBSCAN (`eps`, `min_samples`, доля шума)

Опционально: третий метод / дополнительные варианты параметров.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, `k=2`
- Метрики (silhouette / DB / CH): 0.522 / 0.685 / 11786.95
- Если был DBSCAN: доля шума и комментарий  
  DBSCAN давал silhouette ниже (≈0.397) при нулевой доле шума, поэтому проиграл KMeans.
- Коротко: масштабирование выровняло признаки, и «шаровая» геометрия KMeans дала максимальное качество.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN, `eps=1.0`, `min_samples=20`
- Метрики (silhouette / DB / CH): 0.457 / 0.535 / 72.58
- Если был DBSCAN: доля шума и комментарий  
  Доля шума ≈ 0.011. Нелинейная структура лучше отделяется плотностным методом, чем KMeans.
- Коротко: KMeans не справляется с нелинейной формой кластеров, DBSCAN выделяет плотные области и отделяет выбросы.

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN, `eps=2.5`, `min_samples=20`
- Метрики (silhouette / DB / CH): 0.448 / 0.959 / 5275.91
- Если был DBSCAN: доля шума и комментарий  
  Доля шума ≈ 0.122. Категориальные признаки и пропуски требуют аккуратного препроцессинга.
- Коротко: после imputation + one-hot DBSCAN устойчивее к шуму, чем KMeans, и даёт более интерпретируемые группы.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans «ломается» на нелинейных структурах (dataset-02), так как минимизирует SSE и тянет границы к «шаровым» кластерам.
- DBSCAN выигрывает на данных с нелинейной формой и выбросами, особенно при корректном подборе `eps`.
- Масштабирование было критичным в dataset-01; без него расстояния и метрики деградируют.
- Для dataset-04 ключевыми были обработка пропусков и кодирование категориальных признаков.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости: 5 запусков KMeans на dataset-01 с разными `random_state`.
- Результат: средний ARI между разбиениями = 1.0 (минимум/максимум тоже 1.0).
- Вывод: разбиение устойчиво, KMeans стабильно находит одинаковые кластеры.

### 5.3 Интерпретация кластеров

- Для dataset-01 и dataset-02 интерпретация строилась по геометрии после масштабирования: группы отличаются по сочетаниям базовых признаков (разные «облака»).
- Для dataset-04 влияние категориальных признаков проявляется через one-hot: кластеры отделяются по комбинации категорий и числовых паттернов.
- В целом, для интерпретации удобно смотреть на средние значения числовых признаков в каждом кластере и на частоты категорий (в notebook это возможно без истинных меток).

## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

- Масштабирование критично для distance-based методов (KMeans/DBSCAN).
- KMeans хорошо работает на «шаровых» кластерах, но не на нелинейных формах.
- DBSCAN полезен при выбросах и нелинейных формах, но чувствителен к `eps`.
- Метрики silhouette/DB/CH дают разные перспективы, но согласованно помогают выбирать настройки.
- При DBSCAN важно честно учитывать шум и считать метрики только на non-noise точках.
- Обработка пропусков и категориальных признаков может сильно менять качество.
