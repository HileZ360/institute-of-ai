# Итог выполнения HW05 – бинарная классификация `default` (Dummy vs Logistic Regression)

## Кратко

В ноутбуке `HW05/HW05.ipynb` решается задача бинарной классификации таргета `default` на табличных данных из `S05-hw-dataset.csv`.

Сравниваются:

* бейзлайн: `DummyClassifier(strategy="most_frequent")`
* модель: `Pipeline(StandardScaler -> LogisticRegression)`
* подбор гиперпараметра `C` делается через `GridSearchCV` с оптимизацией по `ROC-AUC`

## Структура

```text
homeworks/
  HW05/
    HW05.ipynb
    README.md
    S05-hw-dataset.csv
    figures/
      roc_curve.png
```

## Данные

Файл: `S05-hw-dataset.csv`

Использование в ноутбуке:

* `client_id` – идентификатор (исключается из признаков)
* `default` – целевая переменная (0/1)

Сводка по датасету (из ноутбука):

* 3000 строк, 17 колонок
* все признаки числовые, пропусков нет
* распределение классов `default`: 0 ≈ 0.590, 1 ≈ 0.410

## Как воспроизвести

### 1) Зависимости

Нужны библиотеки (минимально):

* `pandas`, `numpy`, `matplotlib`
* `scikit-learn`

Установка (пример через pip):

```bash
pip install pandas numpy matplotlib scikit-learn
```

Если используешь `uv`, то `pyproject.toml` лежит в корне репозитория,
поэтому зависимости ставятся так:

```bash
cd <корень-репозитория>
uv sync
```

### 2) Запуск

Открой ноутбук `homeworks/HW05/HW05.ipynb` и выполни все ячейки.

Пример через `uv` (при наличии Jupyter):

```bash
cd <корень-репозитория>
uv run jupyter lab
```

Важно про пути:

* в ноутбуке CSV ищется в текущей директории и в `homeworks/HW05/`
* график сохраняется в папку `figures/` рядом с найденным CSV

Поэтому при запуске нужно, чтобы:

* файл `S05-hw-dataset.csv` был доступен либо в текущей директории, либо в `homeworks/HW05/`
* папка `figures/` создаётся автоматически рядом с найденным CSV

Если при запуске возникает `FileNotFoundError`, исправь одним из способов:

* запускать ноутбук так, чтобы рабочей директорией был корень проекта (где лежит `S05-hw-dataset.csv`)
* либо скорректировать пути в ноутбуке (например, `../S05-hw-dataset.csv`), если рабочая директория – `HW05/`

## Методология

### Разбиение

* признаки: `X = df.drop(columns=["default", "client_id"])` (15 признаков)
* таргет: `y = df["default"]`
* `train_test_split(test_size=0.2, random_state=42, stratify=y)`

  * train: 2400 объектов
  * test: 600 объектов

### Бейзлайн

`DummyClassifier(strategy="most_frequent")`

* `Accuracy ≈ 0.590`
* `ROC-AUC ≈ 0.500`

Интерпретация:

* accuracy соответствует доле большинства (класс 0)
* ROC-AUC на уровне случайного угадывания, так как модель не использует признаки

### Модель

Пайплайн:

* `StandardScaler()`
* `LogisticRegression(max_iter=1000)`

Подбор `C`:

* `GridSearchCV(cv=5, scoring="roc_auc")`
* сетка: `C in [0.01, 0.1, 1.0, 10.0]`

Лучшие параметры (из ноутбука):

* `best C = 10.0`
* `best CV ROC-AUC ≈ 0.861`

## Результаты на тесте

Из ноутбука:

| Модель                      | Accuracy | ROC-AUC |
| --------------------------- | -------- | ------- |
| Dummy (most_frequent)       | 0.590    | 0.500   |
| LogisticRegression (best C) | 0.800    | 0.876   |

Прирост метрик относительно Dummy:

* `accuracy`: +0.210
* `ROC-AUC`: +0.376

Также строятся ROC-кривые и сохраняются в файл:

* `homeworks/HW05/figures/roc_curve.png`

## Вывод

Логистическая регрессия с масштабированием признаков и подбором `C` существенно превосходит бейзлайн по `accuracy` и (особенно) по `ROC-AUC`, поэтому её целесообразно выбирать как итоговую модель для данной постановки задачи.
